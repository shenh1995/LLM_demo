import json
import logging
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
import os
import sys

# æ·»åŠ  backend ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.agent import Agent, AgentConfig
from models.factory import ChatModelFactory
from utils import utils
from config import config


# é…ç½®æ—¥å¿—ä¸ºç»ˆç«¯è¾“å‡º
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()  # è¾“å‡ºåˆ°ç»ˆç«¯
    ]
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
COLUMN_LIST_MARK = "è¡¨å­—æ®µä¿¡æ¯"

def extract_last_json(text: str) -> Optional[str]:
    """ä»æ–‡æœ¬ä¸­æå–æœ€åä¸€ä¸ªJSONå­—ç¬¦ä¸²"""
    import re
    # æŸ¥æ‰¾æœ€åä¸€ä¸ªJSONå¯¹è±¡
    logger.debug(f"ğŸ”„ å¼€å§‹æå–JSON: {text}")
    json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
    matches = re.findall(json_pattern, text)
    logger.info(f"ğŸ”„ æå–JSONç»“æœ: {matches}")
    if matches:
        return matches[-1]
    return None

class VectorSearch:
    """å‘é‡æœç´¢ç±»"""
    
    def __init__(self, 
                 agent_decode_question=None,
                 agent_column_selector=None,
                 agent_fix_column_selection=None,
                 enable_vector_search=True,
                 get_relevant_table_columns=None,
                 print_table_column=None,
                 name="VectorSearch"):
        """
        åˆå§‹åŒ–å‘é‡æœç´¢
        
        Args:
            agent_decode_question: é—®é¢˜è§£ç ä»£ç†
            agent_column_selector: å­—æ®µé€‰æ‹©ä»£ç†
            agent_fix_column_selection: å­—æ®µé€‰æ‹©ä¿®å¤ä»£ç†
            enable_vector_search: æ˜¯å¦å¯ç”¨å‘é‡æœç´¢
            name: æœç´¢å™¨åç§°
        """
        self.agent_decode_question = agent_decode_question
        self.agent_column_selector = agent_column_selector
        self.agent_fix_column_selection = agent_fix_column_selection
        self.enable_vector_search = enable_vector_search
        self.name = name
        self.get_relevant_table_columns = get_relevant_table_columns
        self.print_table_column = print_table_column
        
        # åˆå§‹åŒ–å‘é‡ç›¸å…³ç»„ä»¶
        self.column_vectors = None
        self.column_vector_names = []
        self.column_bm25 = None
        
    def load_vectors(self, cache_dir: str):
        """åŠ è½½å‘é‡æ•°æ®"""
        try:
            # åŠ è½½åˆ—å‘é‡
            if os.path.exists(f"{cache_dir}/column_vectors.npy"):
                self.column_vectors = np.load(f"{cache_dir}/column_vectors.npy")
                
            # åŠ è½½åˆ—å‘é‡åç§°
            if os.path.exists(f"{cache_dir}/column_vector_names.json"):
                with open(f"{cache_dir}/column_vector_names.json", 'r', encoding='utf-8') as f:
                    self.column_vector_names = json.load(f)
                    
            # åŠ è½½BM25æ¨¡å‹
            if os.path.exists(f"{cache_dir}/column_bm25.pkl"):
                import joblib
                self.column_bm25 = joblib.load(f"{cache_dir}/column_bm25.pkl")
                
        except Exception as e:
            logger.warning(f"åŠ è½½å‘é‡æ•°æ®å¤±è´¥: {e}")
    
    
    def validate_column_filter(self, column_filter: Dict[str, Any]) -> str:
        """
        éªŒè¯å­—æ®µè¿‡æ»¤å™¨
        
        Args:
            column_filter: å­—æ®µè¿‡æ»¤å™¨
            
        Returns:
            é”™è¯¯ä¿¡æ¯ï¼Œå¦‚æœéªŒè¯é€šè¿‡è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        if not isinstance(column_filter, dict):
            return "å­—æ®µè¿‡æ»¤å™¨å¿…é¡»æ˜¯å­—å…¸æ ¼å¼"
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„éªŒè¯é€»è¾‘
        return ""
    
    def vector_search(self, messages: List[Dict[str, Any]], first_user_msg: str) -> Tuple[Dict[str, Any], int]:
        """
        å‘é‡+è¯é¢‘æœç´¢
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            first_user_msg: ç¬¬ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            (å­—æ®µè¿‡æ»¤å™¨, ä½¿ç”¨çš„tokenæ•°)
        """
        local_usage_tokens = 0
        column_filter = {}
        
        if not self.enable_vector_search:
            return column_filter, local_usage_tokens

        # è§£ç é—®é¢˜
        # å°†é—®é¢˜æ‹†åˆ†ä¸ºå­é—®é¢˜
        if self.agent_decode_question and messages:
            answer, tk_cnt = self.agent_decode_question.answer("æé—®:\n" + messages[-1]["content"])
            #æ‹†åˆ†æˆåŠŸ
            question_list = [q.strip() for q in answer.split("\n") if q.strip() != ""]
            local_usage_tokens += tk_cnt
        else:
            question_list = [first_user_msg]
        
        # æœç´¢æ•°æ®å­—æ®µ
        if self.get_relevant_table_columns is None:
            logger.warning("get_relevant_table_columns å‡½æ•°æœªè®¾ç½®ï¼Œè·³è¿‡å‘é‡æœç´¢")
            return column_filter, local_usage_tokens

        logger.info(f"âœ… æœç´¢æ•°æ®å­—æ®µ: {question_list}")
        table_columns = self.get_relevant_table_columns(question_list)
        table_columns_str = (
            f"å·²å–å¾—å¯ç”¨çš„{COLUMN_LIST_MARK}:\n" +
            "\n---\n".join([self.print_table_column(table_column) for table_column in table_columns]) +
            "\n"
        )

        # ç­›é€‰å­—æ®µ
        error_msgs = []
        org_answer = ""
        
        for _ in range(5):
            try:
                if len(error_msgs) == 0 or len(column_filter) == 0:
                    if self.agent_column_selector:
                        answer, tk_cnt = self.agent_column_selector.answer((
                            table_columns_str +
                            f"\nç”¨æˆ·é—®é¢˜:\n<{first_user_msg}>" +
                            ("\nè¯·æ³¨æ„:\n" + "\n".join(error_msgs) if len(error_msgs) > 0 else "") +
                            "\nè¯·ä»å·²çŸ¥çš„è¡¨å­—æ®µä¿¡æ¯ä¸­é€‰æ‹©columnï¼Œç¡®ä¿æ­£ç¡®åœ°è¡¨å­—æ®µå…³ç³»ï¼Œç¡®ä¿JSONæ ¼å¼æ­£ç¡®ã€‚"
                        ))
                        org_answer = answer
                        local_usage_tokens += tk_cnt
                    else:
                        break
                else:
                    if self.agent_fix_column_selection:
                        answer, tk_cnt = self.agent_fix_column_selection.answer((
                            table_columns_str +
                            f"\nç”¨æˆ·é—®é¢˜:\n<{first_user_msg}>\n" +
                            f"åŸagentçš„è¾“å‡º:\n'''\n{org_answer}\n'''\n" +
                            ("\nè¯·æ³¨æ„:\n" + "\n".join(error_msgs) if len(error_msgs) > 0 else "") +
                            "\nè¯·ä¿®æ­£ï¼Œç¡®ä¿æ­£ç¡®çš„è¡¨å­—æ®µå…³ç³»ï¼Œç¡®ä¿JSONæ ¼å¼æ­£ç¡®ã€‚"
                        ))
                        local_usage_tokens += tk_cnt
                    else:
                        break
                
                args_json = extract_last_json(answer)
                if args_json is not None:
                    try:
                        tmp_column_filter = json.loads(args_json)
                        column_filter = tmp_column_filter
                        error_msg = self.validate_column_filter(column_filter)
                        if error_msg != "":
                            raise Exception(error_msg)
                        break
                    except json.JSONDecodeError as e:
                        raise Exception(f"JSONè§£æå¤±è´¥: {e}")
                        
            except Exception as e:
                error_msgs.append(str(e))
                print(f"\nç”¨æˆ·é—®é¢˜:\n<{first_user_msg}>\nWorkflowã€{self.name}ã€‘agent_column_selector é‡åˆ°é—®é¢˜: {str(e)}, ç°åœ¨é‡è¯•...\n")
                logger.debug("\nç”¨æˆ·é—®é¢˜:\n<%s>\nWorkflowã€%sã€‘agent_column_selector é‡åˆ°é—®é¢˜: %s, ç°åœ¨é‡è¯•...\n", 
                           first_user_msg, self.name, str(e))
        
        return column_filter, local_usage_tokens
    
    def search(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œå‘é‡æœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if self.column_vectors is None or self.column_bm25 is None:
            logger.warning("å‘é‡æ•°æ®æœªåŠ è½½ï¼Œæ— æ³•æ‰§è¡Œæœç´¢")
            return []
        
        try:
            # ä½¿ç”¨ HuggingFaceEmbedding è¿›è¡ŒæŸ¥è¯¢
            from embedding.embedding import HuggingFaceEmbedding
            import numpy as np
            from sklearn.metrics.pairwise import cosine_similarity
            
            # åˆå§‹åŒ– embedding æ¨¡å‹
            embedder = HuggingFaceEmbedding(model="shibing624/text2vec-base-chinese")
            
            # è·å–æŸ¥è¯¢æ–‡æœ¬çš„ embedding
            query_embedding = embedder.get_embedding([query])[0]
            query_vector = np.array(query_embedding).reshape(1, -1)
            
            logger.info(f"âœ… æŸ¥è¯¢æ–‡æœ¬çš„ embedding: {query_vector}")
            logger.info(f"âœ… æŸ¥è¯¢æ–‡æœ¬çš„ embedding: {len(self.column_vectors)}")
            # è®¡ç®—ä¸æ‰€æœ‰å­˜å‚¨å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
            similarities = cosine_similarity(query_vector, self.column_vectors)
            
            # è·å–æœ€ç›¸ä¼¼çš„ top_k ä¸ªç»“æœ
            top_indices = np.argsort(similarities[0])[::-1][:top_k]
            
            # æ„å»ºç»“æœ
            results = []
            for idx in top_indices:
                similarity_score = similarities[0][idx]
                column_name = self.column_vector_names[idx]
                
                # è§£æè¡¨åå’Œå­—æ®µå
                if '.' in column_name:
                    table_name, field_name = column_name.split('.', 1)
                else:
                    table_name, field_name = column_name, ''
                
                results.append({
                    'column_name': column_name,
                    'table_name': table_name,
                    'field_name': field_name,
                    'similarity_score': float(similarity_score),
                    'rank': len(results) + 1
                })
            
            logger.info(f"âœ… å‘é‡æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
            return []


def main():
    """æµ‹è¯•VectorSearchç±»çš„ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯• VectorSearch ç±»...")
    
    # VectorSearchå®ä¾‹
    vector_search = VectorSearch(
        get_relevant_table_columns=utils.get_relevant_table_columns,
        print_table_column=utils.print_table_column,
        agent_decode_question=Agent(AgentConfig(
            name = "decode_question",
            role = (
                '''ä½ æ˜¯é‡‘èè¡Œä¸šçš„æ•°æ®ä¸“å®¶ï¼Œå–„äºç†è§£ç”¨æˆ·çš„é—®é¢˜ï¼Œä»å·²çŸ¥çš„æ•°æ®è¡¨ä¸­å®šä½åˆ°æœ€ç›¸å…³çš„æ•°æ®è¡¨ã€‚\n'''
                '''å°†åŸé—®é¢˜æ‹†æˆå¤šä¸ªå­é—®é¢˜ï¼Œæ¯ä¸ªå­é—®é¢˜å¯¹åº”ä¸€ä¸ªæ•°æ®è¡¨ã€‚\n'''
                '''å­é—®é¢˜åº”è¯¥éµå¾ªåŸé—®é¢˜çš„è¯­å¢ƒï¼Œå­é—®é¢˜è·å–åˆ°çš„ä¿¡æ¯åº”è¯¥ä¸åŸé—®é¢˜ç›¸å…³ã€‚\n'''
                '''åŸé—®é¢˜ä¸­çš„æ ¼å¼è¦æ±‚å¯ä»¥ä¸ç”¨å†™åˆ°å­é—®é¢˜ä¸­ã€‚\n'''
                '''å¦‚æœåŸé—®é¢˜ä¸­åŒ…å«ä¸“ä¸šæœ¯è¯­çš„ç¼©å†™å’Œå…¨ç§°å’Œä¸­æ–‡ç¿»è¯‘ï¼Œè¯·åœ¨å­é—®é¢˜ä¸­æŠŠä¸“ä¸šæœ¯è¯­çš„ç¼©å†™å’Œå…¨ç§°å’Œä¸­æ–‡ç¿»è¯‘éƒ½å†™ä¸Šã€‚\n'''
            ),
            output_format=(
                '''è¾“å‡ºæ¨¡æ¿ï¼š\n'''
                '''(æ¢è¡Œé¡ºåºè¾“å‡ºå­é—®é¢˜ï¼Œä¸è¦æœ‰æ ‡å·,ç›´æ¥è¾“å‡ºä¸€è¡Œä¸€æ¡å­é—®é¢˜ï¼Œç›´åˆ°è¦†ç›–å®ŒåŸé—®é¢˜ä¸ºæ­¢)\n'''
                '''(ä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹)\n'''
            ),
            system_prompt_kv={
                "ä¸¾ä¾‹": (
                    '''åŸé—®é¢˜ï¼šäº¤æ˜“æ—¥åœ¨2021-10-01åˆ°2021-10-31ä¹‹é—´ï¼Œè¿‘ä¸€æœˆæ¢æ‰‹ç‡è¶…è¿‡10%çš„æ¸¯è‚¡ä¸­è‚¡ä»·ä¸‹è·Œæœ€å¤šçš„å…¬å¸æ˜¯å“ªå®¶ï¼Ÿè¯·å›ç­”å…¬å¸ä¸­æ–‡ç®€ç§°ã€‚\n'''
                    '''è¾“å‡º:\n'''
                    '''äº¤æ˜“æ—¥åœ¨2021-10-01åˆ°2021-10-31ä¹‹é—´çš„æ¸¯è‚¡æœ‰å“ªäº›\n'''
                    '''è¿‘ä¸€æœˆæ¢æ‰‹ç‡è¶…è¿‡10%çš„æ¸¯è‚¡æœ‰å“ªäº›\n'''
                    '''æ¸¯è‚¡è‚¡ä»·ä¸‹è·Œæœ€å¤šçš„å…¬å¸æœ‰å“ªäº›\n'''
                    '''è¿™äº›æ¸¯è‚¡å…¬å¸çš„ä¸­æ–‡ç®€ç§°æ˜¯ä»€ä¹ˆ\n'''
                    # '''åŸé—®é¢˜ï¼šæˆªè‡³2021-12-31ï¼Œè¿™ä¸ªæ¦‚å¿µæœ‰å¤šå°‘åªè‚¡ç¥¨ï¼ˆä¸åŒ…å«å·²ç»è°ƒå‡ºçš„ï¼‰ï¼Ÿè°ƒå‡ºäº†å¤šå°‘åªè‚¡ç¥¨ï¼Ÿ\n'''
                    # '''è¾“å‡º:\n'''
                    # '''æˆªè‡³2021-12-31ï¼Œè¿™ä¸ªæ¦‚å¿µæœ‰å¤šå°‘åªè‚¡ç¥¨ï¼ˆä¸åŒ…å«å·²ç»è°ƒå‡ºçš„ï¼‰\n'''
                    # '''æˆªæ­¢2021-12-31ï¼Œè¿™ä¸ªæ¦‚å¿µè°ƒå‡ºäº†å¤šå°‘åªè‚¡ç¥¨\n'''
                    '''åŸé—®é¢˜ï¼šä¸­å—ä¼ åª’åœ¨2019å¹´åº¦çš„å‰äº”å¤§å®¢æˆ·ä¸­ï¼Œå„ç±»å‹å®¢æˆ·å æ€»è¥æ”¶çš„æ¯”ä¾‹åˆ†åˆ«æ˜¯å¤šå°‘ï¼Ÿï¼ˆç­”æ¡ˆéœ€è¦åŒ…å«ä¸¤ä½å°æ•°ï¼‰\n'''
                    '''è¾“å‡º:\n'''
                    '''ä¸­å—ä¼ åª’åœ¨2019å¹´åº¦çš„å‰äº”å¤§å®¢æˆ·æœ‰å“ªäº›\n'''
                    '''å‰äº”å¤§å®¢æˆ·çš„ç±»å‹æœ‰å“ªäº›\n'''
                    '''å„ç±»å‹å®¢æˆ·å æ€»è¥æ”¶çš„æ¯”ä¾‹æ˜¯å¤šå°‘\n'''
                ),
            },
            model_name="qianwen",
            knowledge=config.table_snippet,
            enable_history=False,
            # stream=False,
        )),
        agent_column_selector=Agent(AgentConfig(
            name = "Check_db_structure.columns_selector",
            model_name="qianwen",
            role = (
                '''ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ï¼Œä»å·²çŸ¥çš„æ•°æ®è¡¨å­—æ®µä¸­ï¼Œæ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œæ‰¾å‡ºæ‰€æœ‰ç›¸å…³çš„å­—æ®µåã€‚'''
                '''è¯·ä¸è¦æœ‰é—æ¼!'''
                '''è¦å–„äºåˆ©ç”¨å†å²å¯¹è¯ä¿¡æ¯å’Œå†å²SQLæŸ¥è¯¢è®°å½•æ¥æ´å¯Ÿå­—æ®µé—´çš„å…³ç³»ã€‚'''
            ),
            output_format = (
                '''è¾“å‡ºæ¨¡æ¿ç¤ºä¾‹:\n'''

                '''ã€æ€ç»´é“¾ã€‘\n'''
                '''(think step by step, åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œç»“åˆç”¨æˆ·æä¾›çš„å¯ç”¨æ•°æ®å­—æ®µï¼Œæ€è€ƒç”¨å“ªäº›å­—æ®µè·å¾—ä»€ä¹ˆæ•°æ®ï¼Œæœ‰æ›´å¥½çš„å­—æ®µå°±é€‰æ›´å¥½çš„å­—æ®µï¼Œé€æ­¥æ¨ç†ç›´è‡³å¯ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜)\n'''
                '''(å¯ä»¥ç”¨sqlæ¨¡æ‹Ÿä¸€ä¸‹ï¼Œçœ‹æµç¨‹æ˜¯å¦åˆç†)\n'''
                # '''(ä¾‹å¦‚: \n'''
                # '''ç”¨æˆ·é—®: 2021å¹´æœ«ï¼Œäº¤é€šè¿è¾“ä¸€çº§è¡Œä¸šä¸­æœ‰å‡ ä¸ªè‚¡ç¥¨ï¼Ÿ\n'''
                # '''æ€ç»´é“¾ï¼š\n'''
                # '''ç”¨æˆ·é—®çš„æ˜¯äº¤é€šè¿è¾“ä¸€çº§è¡Œä¸šï¼Œå¯ä»¥ç”¨lc_exgindchangeè¡¨çš„FirstIndustryNameå­—æ®µå¯ä»¥æ‰¾åˆ°äº¤é€šè¿è¾“ä¸€çº§è¡Œä¸šçš„è¡Œä¸šä»£ç FirstIndustryCode;\n'''
                # '''ç”¨æˆ·éœ€è¦è·å–è¯¥è¡Œä¸šæœ‰å‡ ä¸ªè‚¡ç¥¨ï¼Œåœ¨lc_indfinindicatorsè¡¨é€šè¿‡IndustryCodeå­—æ®µå’ŒStandardå­—æ®µæœç´¢åˆ°äº¤é€šè¿è¾“ä¸€çº§è¡Œä¸šçš„ä¿¡æ¯,'''
                # '''å…¶ä¸­lc_indfinindicatorsè¡¨çš„ListedSecuNumå­—æ®µå°±æ˜¯ä¸Šå¸‚è¯åˆ¸æ•°é‡ï¼Œ\n'''
                # '''ç”±äºç”¨æˆ·é—®çš„æ˜¯2021å¹´æœ«ï¼Œæ‰€ä»¥æˆ‘éœ€è¦ç”¨lc_indfinindicatorsè¡¨çš„InfoPublDateå­—æ®µæ’åºè·å¾—2021å¹´æœ«æœ€åä¸€ç»„æ•°æ®)\n'''

                '''ã€é€‰ä¸­çš„å­—æ®µçš„æ¸…å•ã€‘\n'''
                '''(ä¸Šè¿°æåˆ°çš„å­—æ®µéƒ½é€‰ä¸Š)\n'''
                '''(æŠŠåŒä¸€ä¸ªè¡¨çš„å­—æ®µèšåˆåœ¨è¿™ä¸ªè¡¨å[database_name.table_name]ä¸‹é¢)\n'''
                '''(æ³¨æ„è¡¨åå’Œå­—æ®µåéƒ½æ˜¯è‹±æ–‡çš„)\n'''
                '''```json\n'''
                '''{"database_name.table_name": ["column_name", "column_name"],"database_name.table_name": ["column_name", "column_name"]}\n'''
                '''```\n'''
            ),
            enable_history=False,
            # temperature=0.8,
            # stream=False,
        )),
        agent_fix_column_selection=Agent(AgentConfig(
            name = "fix_column_selection",
            model_name="qianwen",
            role = (
                '''ä½ æ˜¯é‡‘èæ•°æ®åº“ä¸“å®¶ï¼Œè´Ÿè´£å®¡æ ¸å’Œä¿®æ­£å…¶ä»–agenté€‰æ‹©çš„æ•°æ®è¡¨å’Œå­—æ®µã€‚\n'''
                '''ä½ çš„ä¸»è¦ä»»åŠ¡æ˜¯ç¡®ä¿æ‰€æœ‰è¡¨åå’Œå­—æ®µåçš„å‡†ç¡®æ€§ï¼Œä»¥åŠå®ƒä»¬ä¹‹é—´çš„æ­£ç¡®å…³è”ã€‚\n'''
                '''ä½ éœ€è¦ä»”ç»†æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š\n'''
                '''1. å­—æ®µåæ˜¯å¦æ‹¼å†™æ­£ç¡® - å¦‚æœå‘ç°é”™è¯¯ï¼Œè¯·æä¾›æ­£ç¡®çš„å­—æ®µå\n'''
                '''2. è¡¨åä¸å­—æ®µåçš„å…³è”æ˜¯å¦æ­£ç¡® - ç¡®ä¿å­—æ®µç¡®å®å±äºæŒ‡å®šçš„è¡¨\n'''
                '''3. è¡¨ä¹‹é—´çš„å…³è”é”®æ˜¯å¦æ­£ç¡® - æ£€æŸ¥JOINæ¡ä»¶ä¸­ä½¿ç”¨çš„å­—æ®µæ˜¯å¦åˆé€‚\n'''
                '''4. æ•°æ®ç±»å‹æ˜¯å¦åŒ¹é… - ç¡®ä¿æŸ¥è¯¢æ¡ä»¶ä¸­çš„æ•°æ®ç±»å‹ä¸å­—æ®µç±»å‹ä¸€è‡´\n'''
                '''5. æ˜¯å¦é—æ¼äº†é‡è¦çš„è¡¨æˆ–å­—æ®µ - æ ¹æ®ç”¨æˆ·é—®é¢˜è¡¥å……å¯èƒ½æœ‰ç”¨çš„ä¿¡æ¯\n'''
                '''è¯·åŸºäºå·²çŸ¥çš„æ•°æ®åº“ç»“æ„ä¿¡æ¯ï¼Œå¯¹å…¶ä»–agentçš„é€‰æ‹©è¿›è¡Œä¿®æ­£ï¼Œç¡®ä¿æœ€ç»ˆä½¿ç”¨çš„è¡¨å’Œå­—æ®µèƒ½å¤Ÿå‡†ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n'''
                '''å¦‚æœå‘ç°å¤šä¸ªå¯èƒ½çš„ä¿®æ­£æ–¹æ¡ˆï¼Œè¯·é€‰æ‹©æœ€å¯èƒ½æ­£ç¡®çš„ä¸€ä¸ªï¼Œå¹¶ç®€è¦è¯´æ˜ç†ç”±ã€‚\n'''
            ),
            output_format = (
                '''è¾“å‡ºæ¨¡æ¿ç¤ºä¾‹:\n'''
                '''ã€é€‰ä¸­çš„å­—æ®µçš„æ¸…å•ã€‘\n'''
                '''(æŠŠåŒä¸€ä¸ªè¡¨çš„å­—æ®µèšåˆåœ¨è¿™ä¸ªè¡¨å[database_name.table_name]ä¸‹é¢)\n'''
                '''(æ³¨æ„è¡¨åå’Œå­—æ®µåéƒ½æ˜¯è‹±æ–‡çš„)\n'''
                '''```json\n'''
                '''{"database_name.table_name": ["column_name", "column_name"],"database_name.table_name": ["column_name", "column_name"]}\n'''
                '''```\n'''
            ),
            enable_history=False,
            # stream=False,
        )),
        enable_vector_search=True,
        name="TestVectorSearch"
    )
    
    # æµ‹è¯•å‘é‡æœç´¢
    print("\nğŸ” æµ‹è¯•å‘é‡æœç´¢:")
    messages = [
        {"role": "user", "content": "å¤©å£«åŠ›åœ¨2020å¹´çš„æœ€å¤§æ‹…ä¿é‡‘é¢æ˜¯å¤šå°‘ï¼Ÿç­”æ¡ˆéœ€è¦åŒ…å«1ä½å°æ•°"}
    ]
    first_user_msg = "æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯"
    
    try:
        column_filter, usage_tokens = vector_search.vector_search(messages, first_user_msg)
        print(f"âœ… å‘é‡æœç´¢å®Œæˆ")
        print(f"ğŸ“Š ä½¿ç”¨çš„tokenæ•°: {usage_tokens}")
        print(f"ğŸ“‹ å­—æ®µè¿‡æ»¤å™¨: {column_filter}")
    except Exception as e:
        print(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
    
    print("\nâœ… VectorSearch æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()